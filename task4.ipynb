{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Task 4"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Find emoticons in posts and post comments (negative, positive, neutral) (you can use external libraries or predefined emoticon lists) (use the spark udf and broadcast function for emoticons)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import findspark\nimport pyspark\nimport pyspark.sql.functions\nimport pyspark.sql.types\nimport emojis\nimport os",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# pyspark import as regular library\nos.environ[\"SPARK_HOME\"] = \"C:/spark\"\nfindspark.init()",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# pyspark session and SQL context creation\nconfigs = pyspark.SparkConf().setAppName(\"task4\").setMaster(\"local\")\nspark_context = pyspark.SparkContext(conf=configs)\nspark = pyspark.sql.SparkSession(spark_context)\nsql_context = pyspark.sql.SQLContext(spark_context)",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Function to extract emojis defenition\nemojis_extraction = \\\n    pyspark.sql.functions.udf(lambda text: list(emojis.get(text)), \n                              pyspark.sql.types.ArrayType(pyspark.sql.types.StringType()))",
      "execution_count": 50,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Posts data loading where text is not Null\ndata_posts = sql_context.read.json(\"posts_api.json/*.json\").\\\n    where(pyspark.sql.functions.col(\"text\").isNotNull())\n\n# Emojis data creation\ndata_emojis = data_posts.select(\"key\", emojis_extraction(\"text\").alias(\"emojis\")).\\\n    where(pyspark.sql.functions.size(pyspark.sql.functions.col(\"emojis\")) > 0).sort(\"key\")\n\n# Emojis data showing\ndata_emojis.show()\n\n# Emojis data saving\ndata_emojis.coalesce(1).write.format(\"json\").mode(\"overwrite\").save(\"task4_output.json\")",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+---------+------------+\n|      key|      emojis|\n+---------+------------+\n|-94_14693|         [❗]|\n|-94_15804|      [🇮🇹]|\n|-94_16596|        [🎈]|\n|-94_17167|        [🎄]|\n|-94_17381|        [🎄]|\n|-94_17386|        [😺]|\n|-94_17432|    [🎄, 💌]|\n|-94_17447|        [🎓]|\n|-94_17483|        [👆]|\n|-94_17530|         [✨]|\n|-94_17584|        [👪]|\n|-94_17835|[🎨, 💐, 🌸]|\n|-94_18861|        [🎈]|\n|-94_20299|        [😊]|\n|-94_23588|        [😜]|\n|-94_23605|        [😉]|\n|-94_23722|        [😉]|\n|-94_26766|    [😃, 🚴]|\n|-94_26776|        [📌]|\n|-94_26794|        [🔎]|\n+---------+------------+\nonly showing top 20 rows\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}